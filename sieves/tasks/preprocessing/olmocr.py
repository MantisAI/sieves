import json
import os
import subprocess
import tempfile
import warnings
from collections.abc import Iterable
from pathlib import Path
from typing import Any

from tqdm import tqdm

from sieves.data.doc import Doc
from sieves.tasks.core import Task


class OlmOCR(Task):
    """Parser wrapping the olmocr library to convert PDF files into linearized text."""

    def __init__(
        self,
        task_id: str | None = None,
        show_progress: bool = True,
        include_meta: bool = False,
        workspace_dir: str | Path | None = None,
        target_longest_image_dim: int = 1280,
        model: str = "allenai/molmo-o-0425-qa",
        **kwargs: dict[str, Any],
    ):
        """Initialize the olmocr parser.
        :param task_id: Task ID.
        :param show_progress: Whether to show progress bar for processed documents.
        :param include_meta: Whether to include meta information generated by the task.
        :param workspace_dir: Directory to use for temporary olmocr workspace.
        :param target_longest_image_dim: Target longest dimension for PDF page images.
        :param model: Model to use for OCR and layout analysis.
        :param kwargs: Additional kwargs to pass to olmocr pipeline.
        """
        super().__init__(task_id=task_id, show_progress=show_progress, include_meta=include_meta)
        self._workspace_dir = workspace_dir or tempfile.mkdtemp(prefix="olmocr_workspace_")
        self._target_longest_image_dim = target_longest_image_dim
        self._model = model
        self._pipeline_args = kwargs or {}

    def __call__(self, docs: Iterable[Doc]) -> Iterable[Doc]:
        """Parse PDF resources using olmocr.
        :param docs: Resources to process.
        :return: Parsed documents.
        """
        docs = list(docs)

        # Validate docs.
        have_text = False
        for doc in docs:
            assert doc.uri, ValueError("Documents must have a value for .uri.")
            if doc.text:
                have_text = True
        if have_text:
            warnings.warn(f"Task {self._task_id} is about to overwrite existing .text values.")

        # Wrap conversion in TQDM if progress should be shown.
        iterable = tqdm(docs, total=len(docs)) if self._show_progress else docs

        for doc in iterable:
            try:
                pdf_path = doc.uri

                # Ensure the workspace directory exists
                os.makedirs(self._workspace_dir, exist_ok=True)

                # Run olmocr pipeline on the PDF
                cmd = [
                    "python",
                    "-m",
                    "olmocr.pipeline",
                    str(self._workspace_dir),
                    "--pdfs",
                    str(pdf_path),
                    "--target_longest_image_dim",
                    str(self._target_longest_image_dim),
                    "--model",
                    self._model,
                ]

                # Add any additional pipeline arguments
                for key, value in self._pipeline_args.items():
                    cmd.extend([f"--{key}", str(value)])

                subprocess.run(cmd, check=True, capture_output=True)

                # Find the output JSONL file
                results_dir = Path(self._workspace_dir) / "results"
                output_files = list(results_dir.glob("output_*.jsonl"))

                if not output_files:
                    raise FileNotFoundError(f"No output files found in {results_dir}")

                # Read the first output file (should only be one for a single PDF)
                with open(output_files[0]) as f:
                    output_data = json.loads(f.readline().strip())

                # Extract the text from the output
                linearized_text = output_data.get("text", "")

                # Update the document
                doc.text = linearized_text

                # Set chunks if layout information is available
                if "blocks" in output_data:
                    doc.chunks = [block.get("text", "") for block in output_data["blocks"]]

                # Include metadata if requested
                if self._include_meta:
                    doc.meta |= {self.id: output_data}

            except FileNotFoundError as err:
                raise FileNotFoundError(f"File at {doc.uri} not found. Ensure that this is a local file path.") from err
            except subprocess.CalledProcessError as err:
                warnings.warn(f"Error processing {doc.uri}: {err}")
                # Continue with next document

        return docs

    @property
    def _state(self) -> dict[str, Any]:
        return {
            **super()._state,
            "workspace_dir": self._workspace_dir,
            "target_longest_image_dim": self._target_longest_image_dim,
            "model": self._model,
            **self._pipeline_args,
        }
