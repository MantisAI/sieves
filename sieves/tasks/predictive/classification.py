from typing import Any, Iterable, Optional, TypeAlias

from sieves.data import Doc
from sieves.engines import Engine, EngineType, outlines_engine
from sieves.engines.core import InferenceMode, Model, PromptSignature, Result
from sieves.engines.outlines_engine import Outlines
from sieves.tasks.core import PredictiveTask

# To be amended once more engines are supported.
TaskPromptSignature: TypeAlias = list[str]
TaskInferenceMode: TypeAlias = outlines_engine.InferenceMode
TaskResult: TypeAlias = outlines_engine.Result


class Classification(PredictiveTask[TaskPromptSignature, TaskResult, Model, TaskInferenceMode]):
    def __init__(
        self,
        labels: list[str],
        engine: Engine[PromptSignature, Result, Model, InferenceMode],
        task_id: Optional[str] = None,
        show_progress: bool = True,
        include_meta: bool = True,
    ) -> None:
        """
        Initializes new PredictiveTask.
        :param labels: Labels to predict.
        :param task_id: Task ID.
        :param show_progress: Whether to show progress bar for processed documents.
        :param include_meta: Whether to include meta information generated by the task.
        """
        self._labels = labels
        self._engine = engine
        self._prompt_signature = self._create_prompt_signature()
        super().__init__(engine=engine, task_id=task_id, show_progress=show_progress, include_meta=include_meta)

    @property
    def supports(self) -> set[EngineType]:
        return {EngineType.outlines}

    @property
    def _inference_mode(self) -> TaskInferenceMode:
        match self._engine:
            case Outlines():
                return outlines_engine.InferenceMode.choice
            case _:
                raise ValueError(f"Unsupported engine type: {type(self._engine)}")

    @property
    def prompt_template(self) -> str:
        match self._engine:
            case Outlines():
                return f"""
                Classify the text after ======== as one of the following options: {",".join(self._labels)}.
                ========
                {{{{ text }}}}
                """
            case _:
                raise ValueError(f"Unsupported engine type: {type(self._engine)}")

    def _create_prompt_signature(self) -> TaskPromptSignature:
        match self._engine:
            case Outlines():
                return self._labels
            case _:
                raise ValueError(f"Unsupported engine type: {type(self._engine)}")

    def _extract_from_docs(self, docs: Iterable[Doc]) -> Iterable[dict[str, Any]]:
        # todo Remove slicing once we have chunking support.
        return ({"text": doc.text[:256] if doc.text else None} for doc in docs)

    def _integrate_into_docs(self, results: Iterable[TaskResult], docs: Iterable[Doc]) -> Iterable[Doc]:
        match self._engine:
            case Outlines():
                for doc, result in zip(docs, results):
                    doc.results[self.id] = result
            case _:
                raise ValueError(f"Unsupported engine type: {type(self._engine)}")

        return docs
